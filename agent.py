"""
ç—…ç†è¯Šæ–­ Agent æ‰§è¡Œé€»è¾‘ - åŸºäº LangGraph çš„å›¾ç¼–æ’
"""

from typing import TypedDict, List, Dict, Annotated, Literal, Optional
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver
import operator
import numpy as np
import logging

# å¯¼å…¥æ¨¡å‹ç®¡ç†æ¨¡å—
from model_registry import ModelRegistry
from utils import save_rois

logging.basicConfig(level=logging.INFO, format='%(message)s')
logger = logging.getLogger(__name__)


# ============= 1. å…¨å±€çŠ¶æ€å®šä¹‰ =============

class PathologyState(TypedDict):
    """å…¨å±€çŠ¶æ€ Schema"""
    wsi_path: str                                       # WSI åˆ‡ç‰‡è·¯å¾„
    roi_queue: Annotated[List[Dict], operator.add]     # ROI é˜Ÿåˆ—
    observations: Annotated[List[Dict], operator.add]  # MLLM å½¢æ€å­¦æè¿°
    reflection_log: Annotated[List[str], operator.add] # åæ€æ—¥å¿—
    diagnostics: Dict                                   # è¯Šæ–­ç»“æœï¼ˆæ¥è‡ªæ•°æ®åº“ï¼‰
    current_iteration: int                              # å½“å‰è¿­ä»£æ¬¡æ•°
    max_iterations: int                                 # æœ€å¤§è¿­ä»£é™åˆ¶
    final_report: str                                   # ç—…ç†æŠ¥å‘Š
    slide_id: str                                       # åˆ‡ç‰‡ç¼–å·


# ============= 2. WSI å·¥å…·ç±» =============
from openslide import OpenSlide




class WSIHandler:
    """WSI è¯»å–å’Œåæ ‡ç®¡ç†"""

    def __init__(self, wsi_path: str):
        self.wsi_path = wsi_path
        try:
            self.wsi = OpenSlide(wsi_path)
            self.level_count = self.wsi.level_count
            self.level_dimensions = self.wsi.level_dimensions
            self.level_downsamples = self.wsi.level_downsamples
        except Exception as e:
            logger.error(f"âŒ æ— æ³•æ‰“å¼€ WSI: {e}")
            self.wsi = None

    def extract_roi_patch(self, center_x, center_y, patch_size) -> np.ndarray:
        """ä» WSI æå–æŒ‡å®šå€ç‡çš„ ROI patch"""
        # å°†ä¸­å¿ƒåæ ‡è½¬æ¢ä¸º level 0 åæ ‡ï¼ˆOpenSlide è¦æ±‚ï¼‰
        thumbnail = self.wsi.get_thumbnail((2048, 2048))
        img_array = np.array(thumbnail)
        arr1 = img_array[:]
        width, height, channel = arr1.shape
        original_width, original_hight = self.level_dimensions[0]
        top_left_x = center_x / width * original_width - patch_size // 2
        top_left_y = center_y / width * original_hight - patch_size // 2

        # è¯»å–åŒºåŸŸ
        region = self.wsi.read_region(
            (int(top_left_x), int(top_left_y)),
            0,
            (int(patch_size), int(patch_size))
        )

        # è½¬æ¢ä¸º RGBï¼ˆOpenSlide è¿”å› RGBAï¼‰
        region_rgb = region.convert('RGB')
        return np.array(region_rgb)


    def get_thumbnail(self, size=(2048, 2048)) -> np.ndarray:
        """è·å–ç¼©ç•¥å›¾ç”¨äºå¯¼èˆª"""
        if self.wsi:
            thumbnail = self.wsi.get_thumbnail(size)
            thumbnail_rgb = thumbnail.convert("RGB")
            thumbnail_rgb.save('./roi_region/thumbnail.png', "PNG")
            return np.array(thumbnail)

    def close(self):
        """é‡Šæ”¾ WSI æ–‡ä»¶å¥æŸ„"""
        if self.wsi:
            self.wsi.close()


# ============= 3. LangGraph èŠ‚ç‚¹å®šä¹‰ =============

class PathologyAgent:
    """ç—…ç†è¯Šæ–­ Agent ä¸»ç±»"""

    def __init__(self, model_registry: ModelRegistry):
        self.models = model_registry

    # ----------- èŠ‚ç‚¹ 1: Navigator -----------
    def navigator_node(self, state: PathologyState) -> PathologyState:
        """å¯¼èˆªèŠ‚ç‚¹ï¼šROI æ£€æµ‹"""
        logger.info(f"\n{'='*70}")
        logger.info(f"ğŸ” [Navigator] ç¬¬ {state.get('current_iteration', 0) + 1} è½®å¯¼èˆª")
        logger.info(f"{'='*70}")

        # åªåœ¨ç¬¬ä¸€æ¬¡è¿­ä»£æ‰§è¡Œæ£€æµ‹
        if state.get("current_iteration", 0) == 0:
            wsi = WSIHandler(state['wsi_path'])
            thumbnail = wsi.get_thumbnail()

            logger.info(f"ç¼©ç•¥å›¾å°ºå¯¸æ˜¯ {thumbnail.shape}")



            # è°ƒç”¨ç»Ÿä¸€ APIï¼šæ„ŸçŸ¥å¯¼èˆªå™¨ (Gemini 3 Pro)
            rois = self.models.detect_rois(thumbnail)

            # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
            roi_queue = [
                {
                    "coord": (roi["center_x"], roi["center_y"]),
                    "bbox": roi["bbox"],
                    "mag": 20.0,
                    "confidence": roi["confidence"],
                    "status": "pending",
                    "roi_type": roi["class"]
                }
                for roi in rois
            ]

            # ä¿å­˜roiåŒºåŸŸçš„ç¼©ç•¥å›¾
            save_rois(thumbnail, rois)

            wsi.close()

            logger.info(f"âœ… æ£€æµ‹åˆ° {len(roi_queue)} ä¸ªå€™é€‰ ROI")

            return {
                "roi_queue": roi_queue,
                "current_iteration": 1
            }
        else:
            # åç»­è¿­ä»£åªå¢åŠ è®¡æ•°
            return {"current_iteration": state.get("current_iteration", 0) + 1}

    # ----------- èŠ‚ç‚¹ 2: Sampler -----------
    def sampler_node(self, state: PathologyState) -> PathologyState:
        """é‡‡æ ·èŠ‚ç‚¹ï¼šæå–é«˜å€ç‡ Patch"""
        logger.info(f"\nğŸ“¸ [Sampler] é‡‡æ ·é«˜å€ç‡ Patch...")

        pending = [r for r in state["roi_queue"] if r["status"] == "pending"]
        if not pending:
            logger.warning("âš ï¸ é˜Ÿåˆ—ä¸­æ— å¾…å¤„ç† ROI")
            return {}

        roi = pending[0]
        logger.info(f"   å¤„ç† ROI: {roi['coord']} (ç±»å‹: {roi.get('roi_type', 'unknown')})")

        wsi = WSIHandler(state['wsi_path'])

        # æå– patch
        # todo : patchesæ”¯æŒéå†
        patch = wsi.extract_roi_patch(roi["coord"][0], roi["coord"][1], patch_size=672)

        wsi.close()

        # æ›´æ–°çŠ¶æ€
        updated_queue = state["roi_queue"].copy()
        for r in updated_queue:
            if r["coord"] == roi["coord"] and r["status"] == "pending":
                r["status"] = "sampled"
                r["patch"] = patch
                break

        return {"roi_queue": updated_queue}

    # ----------- èŠ‚ç‚¹ 3: Describer -----------
    def describer_node(self, state: PathologyState) -> PathologyState:
        """æè¿°èŠ‚ç‚¹ï¼šMLLM å½¢æ€å­¦åˆ†æ"""
        logger.info(f"\nğŸ”¬ [Describer] ç”Ÿæˆå½¢æ€å­¦æè¿°...")

        sampled = [r for r in state["roi_queue"] if r["status"] == "sampled"]
        if not sampled:
            logger.warning("âš ï¸ æ— å·²é‡‡æ ·çš„ ROI")
            return {}

        roi = sampled[-1]  # å–æœ€æ–°é‡‡æ ·çš„
        patch = roi.get("patch")

        # è°ƒç”¨ç»Ÿä¸€ APIï¼šè¯­ä¹‰è§£æå‘˜ (Gemini 3 Pro)
        description = self.models.describe_patch(patch)

        observation = {
            "roi_coord": roi["coord"],
            "roi_type": roi.get("roi_type"),
            "description": description,
            "timestamp": state.get("current_iteration")
        }
        logger.info(f"   å½¢æ€å­¦æè¿°: {description.get('completeness_score', 0):.2f}")

        logger.info(f"   å®Œæ•´åº¦è¯„åˆ†: {description.get('completeness_score', 0):.2f}")

        return {"observations": [observation]}

    # ----------- èŠ‚ç‚¹ 4: Reflector -----------
    def reflector_node(self, state: PathologyState) -> PathologyState:
        """åæ€èŠ‚ç‚¹ï¼šè´¨é‡æ£€æŸ¥"""
        logger.info(f"\nğŸ¤” [Reflector] å®¡æŸ¥æè¿°è´¨é‡...")

        if not state["observations"]:
            return {"reflection_log": ["ERROR: æ— è§‚å¯Ÿç»“æœ"]}

        latest_obs = state["observations"][-1]

        # è°ƒç”¨ç»Ÿä¸€ APIï¼šå®¡æ ¸å®¡æŸ¥å‘˜ (Baichuan)
        reflection = self.models.reflect_quality(
            latest_obs["description"],
            goal="subtype+invasion"
        )

        logger.info(f"   è´¨é‡è¯„åˆ†: {reflection.get('quality_score', 0):.2f}")
        logger.info(f"   å†³ç­–: {reflection.get('action', 'UNKNOWN')}")

        if reflection.get("action") == "RE-SCAN":
            # è§¦å‘é‡é‡‡æ ·
            last_roi_coord = latest_obs["roi_coord"]

            logger.warning(f"   âš ï¸ {reflection.get('suggestions', '')}")

            return {
                "reflection_log": [f"âš ï¸ {reflection.get('suggestions', '')}"],
                "roi_queue": [{
                    "coord": last_roi_coord,
                    "mag": 40.0,
                    "status": "pending",
                    "reason": "reflection_rescan"
                }]
            }

        return {"reflection_log": [f"âœ“ {reflection.get('suggestions', '')}"]}

    # ----------- èŠ‚ç‚¹ 5: Diagnosis Query (æ›¿ä»£ PFM + Specialist) -----------
    def diagnosis_query_node(self, state: PathologyState) -> PathologyState:
        """è¯Šæ–­æŸ¥è¯¢èŠ‚ç‚¹ï¼šä»ç¦»çº¿æ•°æ®åº“è·å–è¯Šæ–­ç»“æœ"""
        logger.info(f"\nğŸ—„ï¸ [DiagnosisDB] æŸ¥è¯¢ç¦»çº¿è¯Šæ–­ç»“æœ...")

        if not state["observations"]:
            logger.warning("âš ï¸ æ— è§‚å¯Ÿç»“æœ")
            return {}

        latest_obs = state["observations"][-1]
        roi_coord = latest_obs["roi_coord"]

        # è°ƒç”¨æ•°æ®åº“æŸ¥è¯¢
        diagnosis_result = self.models.query_diagnosis(
            slide_id=state["slide_id"],
            roi_coord=roi_coord
        )

        diagnostics = {
            "subtype": diagnosis_result["subtype"],
            "subtype_confidence": diagnosis_result["subtype_confidence"],
            "invasion_layer": diagnosis_result["invasion_layer"],
            "depth_mm": diagnosis_result["depth_mm"],
            "invasion_confidence": diagnosis_result["invasion_confidence"],
            "model_version": diagnosis_result.get("model_version", "unknown")
        }

        logger.info(f"   ğŸ“Œ æ¨¡å‹ç‰ˆæœ¬: {diagnostics['model_version']}")

        # æ ‡è®°å½“å‰ ROI å®Œæˆ
        updated_queue = state["roi_queue"].copy()
        for r in updated_queue:
            if r["status"] == "sampled":
                r["status"] = "diagnosed"
                break

        return {
            "diagnostics": diagnostics,
            "roi_queue": updated_queue
        }

    # ----------- èŠ‚ç‚¹ 6: Report Generator -----------
    def report_generator_node(self, state: PathologyState) -> PathologyState:
        """æŠ¥å‘Šç”ŸæˆèŠ‚ç‚¹"""
        logger.info(f"\nğŸ“„ [Report Generator] ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š...")

        # è°ƒç”¨ç»Ÿä¸€ APIï¼šæŠ¥å‘Šç”Ÿæˆå™¨ (Baichuan)
        report = self.models.generate_report(
            state["observations"],
            state["diagnostics"],
            slide_id=state.get("slide_id", "UNKNOWN")
        )

        logger.info("   âœ… æŠ¥å‘Šç”Ÿæˆå®Œæˆ")

        return {"final_report": report}


# ============= 4. è·¯ç”±é€»è¾‘ =============

def should_process_roi(state: PathologyState) -> Literal["sampler", "report"]:
    """Navigator åçš„è·¯ç”±"""
    pending = [r for r in state["roi_queue"] if r["status"] == "pending"]

    if pending:
        logger.info(f"ğŸ“‹ å‘ç° {len(pending)} ä¸ªå¾…å¤„ç† ROIï¼Œè¿›å…¥é‡‡æ ·")
        return "sampler"
    else:
        logger.info("âœ… é˜Ÿåˆ—å·²ç©ºï¼Œç›´æ¥ç”ŸæˆæŠ¥å‘Š")
        return "report"


def should_continue_reflection(state: PathologyState) -> Literal["sampler", "diagnosis_query"]:
    """Reflector åçš„è·¯ç”±"""
    if state["reflection_log"] and "âš ï¸" in state["reflection_log"][-1]:
        logger.info("âš ï¸ æè¿°è´¨é‡ä¸è¶³ï¼Œé‡æ–°é‡‡æ ·")
        return "sampler"

    logger.info("âœ“ æè¿°åˆæ ¼ï¼ŒæŸ¥è¯¢è¯Šæ–­æ•°æ®åº“")
    return "diagnosis_query"


def should_iterate(state: PathologyState) -> Literal["navigator", "report"]:
    """Specialist åçš„è·¯ç”±"""
    # æ£€æŸ¥ 1: æ˜¯å¦è¶…è¿‡æœ€å¤§è¿­ä»£æ¬¡æ•°
    if state["current_iteration"] >= state.get("max_iterations", 3):
        logger.info("âš ï¸ è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œç”ŸæˆæŠ¥å‘Š")
        return "report"

    # æ£€æŸ¥ 2: æ˜¯å¦è¿˜æœ‰æœªå¤„ç†çš„ ROI
    pending = [r for r in state["roi_queue"] if r["status"] == "pending"]

    if not pending:
        logger.info("âœ… æ‰€æœ‰ ROI å·²å¤„ç†å®Œæˆï¼Œç”ŸæˆæŠ¥å‘Š")
        return "report"

    logger.info(f"ğŸ”„ è¿˜æœ‰ {len(pending)} ä¸ª ROI å¾…å¤„ç†ï¼Œç»§ç»­è¿­ä»£")
    return "navigator"


# ============= 5. æ„å»ºå›¾ =============

def build_pathology_graph(model_registry: ModelRegistry) -> StateGraph:
    """æ„å»ºå®Œæ•´çš„è¯Šæ–­å›¾"""

    # åˆ›å»º Agent å®ä¾‹
    agent = PathologyAgent(model_registry)

    # æ„å»ºå›¾
    workflow = StateGraph(PathologyState)

    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("navigator", agent.navigator_node)
    workflow.add_node("sampler", agent.sampler_node)
    workflow.add_node("describer", agent.describer_node)
    workflow.add_node("reflector", agent.reflector_node)
    workflow.add_node("diagnosis_query", agent.diagnosis_query_node)  # æ›¿ä»£ pfm_extraction + specialist
    workflow.add_node("report", agent.report_generator_node)

    # å®šä¹‰è¾¹
    workflow.add_conditional_edges(
        "navigator",
        should_process_roi,
        {
            "sampler": "sampler",
            "report": "report"
        }
    )

    workflow.add_edge("sampler", "describer")
    workflow.add_edge("describer", "reflector")

    workflow.add_conditional_edges(
        "reflector",
        should_continue_reflection,
        {
            "sampler": "sampler",
            "diagnosis_query": "diagnosis_query"  # ç›´æ¥æŸ¥è¯¢è¯Šæ–­æ•°æ®åº“
        }
    )

    workflow.add_conditional_edges(
        "diagnosis_query",
        should_iterate,
        {
            "navigator": "navigator",
            "report": "report"
        }
    )

    workflow.add_edge("report", END)

    # è®¾ç½®å…¥å£
    workflow.set_entry_point("navigator")

    # ç¼–è¯‘å›¾
    memory = MemorySaver()
    return workflow.compile(checkpointer=memory)


# ============= 6. ä¸»æ‰§è¡Œå…¥å£ =============

def run_pathology_diagnosis(
    wsi_path: str,
    slide_id: str = "SLIDE-001",
    max_iterations: int = 2,
    model_config: Optional[Dict] = None
) -> Dict:
    """
    æ‰§è¡Œç—…ç†è¯Šæ–­æµç¨‹

    Args:
        wsi_path: WSI æ–‡ä»¶è·¯å¾„
        slide_id: åˆ‡ç‰‡ç¼–å·
        max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°
        model_config: æ¨¡å‹é…ç½®å­—å…¸

    Returns:
        Dict: åŒ…å«æœ€ç»ˆçŠ¶æ€çš„å­—å…¸
    """

    # 1. åˆå§‹åŒ–æ¨¡å‹æ³¨å†Œä¸­å¿ƒ
    logger.info("\n" + "="*70)
    logger.info("ğŸš€ åˆå§‹åŒ–ç—…ç†è¯Šæ–­ç³»ç»Ÿ")
    logger.info("="*70)

    model_registry = ModelRegistry(config=model_config)
    model_registry.load_all()

    # 2. æ„å»ºå›¾
    graph = build_pathology_graph(model_registry)

    # 3. åˆå§‹åŒ–çŠ¶æ€
    initial_state = {
        "wsi_path": "./data/slide/008682e22a74ac4a85b3b3628ef3b775.svs",
        "slide_id": "008682",
        "roi_queue": [],
        "observations": [],
        "reflection_log": [],
        "diagnostics": {},
        "current_iteration": 0,
        "max_iterations": max_iterations,
        "final_report": ""
    }

    # 4. æ‰§è¡Œå›¾
    logger.info("\n" + "="*70)
    logger.info("ğŸ¥ å¼€å§‹ç—…ç†è¯Šæ–­æµç¨‹")
    logger.info("="*70)

    config = {"configurable": {"thread_id": f"diagnosis_{slide_id}"}}

    try:
        final_state = graph.invoke(initial_state, config)

        # 5. è¾“å‡ºç»“æœ
        logger.info("\n" + "="*70)
        logger.info("ğŸ“Š è¯Šæ–­å®Œæˆ")
        logger.info("="*70)
        logger.info(f"\n{final_state['final_report']}\n")
        logger.info("="*70)

        return final_state

    except Exception as e:
        logger.error(f"\nâŒ è¯Šæ–­æµç¨‹å‡ºé”™: {e}\n")
        raise


# ============= 7. å‘½ä»¤è¡Œæ¥å£ =============

if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="ç—…ç†è¯Šæ–­ Agent V11")
    parser.add_argument("--wsi", type=str, required=False, help="WSI æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--slide-id", type=str, default="SLIDE-001", help="åˆ‡ç‰‡ç¼–å·")
    parser.add_argument("--max-iter", type=int, default=25, help="æœ€å¤§è¿­ä»£æ¬¡æ•°")
    parser.add_argument("--gemini-key", type=str, default=None,
                       help="Gemini API Key")
    parser.add_argument("--baichuan-key", type=str, default=None,
                       help="Baichuan API Key")
    parser.add_argument("--db-type", type=str, default="sqlite",
                       choices=["sqlite", "mongodb", "redis"],
                       help="è¯Šæ–­æ•°æ®åº“ç±»å‹")
    parser.add_argument("--db-path", type=str, default="pathology_diagnosis.db",
                       help="æ•°æ®åº“è·¯å¾„ï¼ˆSQLiteï¼‰æˆ–ä¸»æœºåœ°å€")

    args = parser.parse_args()

    # æ„å»ºé…ç½®
    config = {
        "api": {
            "gemini": {
                "api_key": args.gemini_key,
                "model": "gemini-3-pro-preview"
            },
            "baichuan": {
                "api_key": args.baichuan_ke,
                "model": "Baichuan-M3",
                "api_base": "https://api.baichuan-ai.com/v1"
            }
        },
        "database": {
            "type": args.db_type,
            "path": args.db_path if args.db_type == "sqlite" else None,
            "host": args.db_path if args.db_type in ["mongodb", "redis"] else None
        }
    }

    # æ‰§è¡Œè¯Šæ–­
    run_pathology_diagnosis(
        wsi_path=args.wsi,
        slide_id=args.slide_id,
        max_iterations=args.max_iter,
        model_config=config
    )